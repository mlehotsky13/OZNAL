corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
View(corpus)
tdm <- DocumentTermMatrix(corpus)
tdm
weightedtdm <- weightTfIdf(tdm)
inspect(tdm)
inspect(weightedtdm)
inspect(weightedtdm)
tdmTrain <- tdm[which(merged$train_test == "train"),]
weightedTDMtrain <- weightedtdm[which(merged$train_test == "train"),]
tdmTest <-  tdm[which(merged$train_test == "test"),]
weightedTDMtest <- weightedtdm[which(merged$train_test == "test"),]
View(weightedTDMtest)
inspect(weightedTDMtest)
weightedTDMtest$doc.class  <- merged$Class[which(merged$train_test == "test")]
inspect(weightedTDMtest)
vc_p_train_3 <- tm_filter(vc_p_train, FUN = function(x){
if (length(meta(x)[["topics_cat"]] == 1)) {
if ("crude" %in% meta(x)[["topics_cat"]]
| "money-fx" %in% meta(x)[["topics_cat"]]
| "trade" %in% meta(x)[["topics_cat"]]){
return(TRUE);
}
}
return(FALSE);
})
load("3.RData")
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs)
# get subset corpus of train documents
vc_p_train <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
vc_p_train_3 <- tm_filter(vc_p_train, FUN = function(x){
if (length(meta(x)[["topics_cat"]] == 1)) {
if ("crude" %in% meta(x)[["topics_cat"]]
| "money-fx" %in% meta(x)[["topics_cat"]]
| "trade" %in% meta(x)[["topics_cat"]]){
return(TRUE);
}
}
return(FALSE);
})
View(vc_p_train_3)
vc_p_train_3 <- tm_filter(vc_p_train, FUN = function(x){
if (length(meta(x)[["topics_cat"]] == 1)) {
if ("crude" == meta(x)[["topics_cat"]]
| "money-fx" == meta(x)[["topics_cat"]]
| "trade" == meta(x)[["topics_cat"]]){
return(TRUE);
}
}
return(FALSE);
});
View(vc_p_train_3)
View(vc_p_train_3)
vc_p_train_1 <- tm_filter(vc_p_trian, FUN = function(x){length(meta(x)[["topics_cat"]] == 1)})
vc_p_train_1 <- tm_filter(vc_p_train, FUN = function(x){length(meta(x)[["topics_cat"]] == 1)})
remove(vcp_train_3)
remove(vc_p_train_3)
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
});
vc_p_train_1 <- tm_filter(vc_p_train, FUN = function(x){length(meta(x)[["topics_cat"]] == 1)})
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
});
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" == meta(x)[["topics_cat"]]
})
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" %in% meta(x)[["topics_cat"]]
})
View(vc_p_train_1)
load("3.RData")
# get subset corpus of train documents
vc_p_train <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
vc_p_train_1 <- tm_filter(vc_p_train, FUN = function(x){length(meta(x)[["topics_cat"]]) == 1})
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs)
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" %in% meta(x)[["topics_cat"]]
})
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
"crude" %in% meta(x)[["topics_cat"]]  | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
dataframe <- data.frame(text=unlist(sapply(vc_p_one[1:10], `[`, "content")),
topic=unlist(sapply(vc_p_one[1:10], meta, "topics_cat")),
stringsAsFactors=F)
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:10], `[`, "content")),
topic=unlist(sapply(vc_p_train_3[1:10], meta, "topics_cat")),
stringsAsFactors=F)
vc_p_train_3 <- tm_filter(vc_p_train_1, FUN = function(x){
length(meta(x)[["topics_cat"]]) == 1 & "crude" %in% meta(x)[["topics_cat"]]  | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:10], `[`, "content")),
topic=unlist(sapply(vc_p_train_3[1:10], meta, "topics_cat")),
stringsAsFactors=F)
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:10], `[`, "content")),
#topic=unlist(sapply(vc_p_train_3[1:10], meta, "topics_cat")),
stringsAsFactors=F)
View(dataframe)
vc_p_train_1 <- tm_filter(vc_p_train, FUN = function(x){length(meta(x)[["topics_cat"]]) == 1})
vc_p_train_1_non_empty <- tm_filter(vc_p_train_1, FUN = function(x){length(x$content) != 0})
vc_p_train_3 <- tm_filter(vc_p_train_1_non_empty, FUN = function(x){
length(meta(x)[["topics_cat"]]) == 1 & "crude" %in% meta(x)[["topics_cat"]]  | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:10], `[`, "content")),
#topic=unlist(sapply(vc_p_train_3[1:10], meta, "topics_cat")),
stringsAsFactors=F)
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:10], `[`, "content")),
topic=unlist(sapply(vc_p_train_3[1:10], meta, "topics_cat")),
stringsAsFactors=F)
dataframe
View(dataframe)
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:100], `[`, "content")),
topic=unlist(sapply(vc_p_train_3[1:100], meta, "topics_cat")),
stringsAsFactors=F)
View(dataframe)
dataframe <- data.frame(text=unlist(sapply(vc_p_train_3[1:100], `[`, "content")),
topic=unlist(sapply(vc_p_train_3[1:100], meta, "topics_cat")),
stringsAsFactors=F)
View(dataframe)
load("3.RData")
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs)
library(tm)
library(caret)
library(ggplot2)
# function for processing documents inside file
processFile <- function(filepath) {
con = file(filepath, "r")
resultVector <- c()
x <- character()
while ( length(line) != 0 ) {
line = readLines(con, n = 1, encoding = "latin1")
line = gsub("&#\\d+;", "", line)
x = paste(x, line)
if ( length(line) == 0 || (length(line) != 0 && grepl("</REUTERS>", line))){
resultVector <- union(resultVector, c(x))
x <- character()
}
}
close(con)
return(resultVector)
}
# going through every .sgm file in given directory
files <- list.files(path="Dataset/reuters21578/test", pattern="*.sgm", full.names=T, recursive=FALSE)
allDocs <- c()
for (i in 1:length(files)){
docsOfFile <- processFile(files[i])
allDocs <- union(allDocs, docsOfFile)
}
# creating corpus
vs <- VectorSource(allDocs)
vc <- VCorpus(vs, readerControl = list(reader = readReut21578XMLasPlain))
# remove documents with empty content
vc <- tm_filter(vc, FUN = function(x){length(x$content) > 0})
library(tm)
library(caret)
library(ggplot2)
# function for processing documents inside file
processFile <- function(filepath) {
con = file(filepath, "r")
resultVector <- c()
x <- character()
while ( length(line) != 0 ) {
line = readLines(con, n = 1, encoding = "latin1")
line = gsub("&#\\d+;", "", line)
x = paste(x, line)
if ( length(line) == 0 || (length(line) != 0 && grepl("</REUTERS>", line))){
resultVector <- union(resultVector, c(x))
x <- character()
}
}
close(con)
return(resultVector)
}
# going through every .sgm file in given directory
files <- list.files(path="Dataset/reuters21578/test", pattern="*.sgm", full.names=T, recursive=FALSE)
allDocs <- c()
for (i in 1:length(files)){
docsOfFile <- processFile(files[i])
allDocs <- union(allDocs, docsOfFile)
}
# creating corpus
vs <- VectorSource(allDocs)
vc <- VCorpus(vs, readerControl = list(reader = readReut21578XMLasPlain))
# remove documents with empty content
vc <- tm_filter(vc, FUN = function(x){length(x$content) > 0})
# removing unnecessary meta attributes
removeMetaAttributes <- function(x){
PlainTextDocument(x,
id = meta(x, "id"),
topics = meta(x, "topics"),
topics_cat = meta(x, "topics_cat"),
lewissplit = meta(x, "lewissplit"),
cgisplit = meta(x, "cgisplit"))
}
vc <- tm_map(vc, removeMetaAttributes)
# observe documents with and without set topic
topic <- meta(vc, "topics")
topic <- unlist(topic, use.names=FALSE)
topicDt <- as.data.frame(table(topic))
# observe splits to train and test sets according to lewis
ls <- meta(vc, "lewissplit")
ls <- unlist(ls, use.names=FALSE)
lsDt <- as.data.frame(table(ls))
# observe splits to train and test sets according to cgi
cgi <- meta(vc, "cgisplit")
cgi <- unlist(cgi, use.names=FALSE)
cgiDt <- as.data.frame(table(cgi))
# PREPROCESSING of text contents
vc_p <- vc
# transform content of documents to lower case
vc_p <- tm_map(vc_p, content_transformer(tolower))
# transform content of documents by removal of numbers
vc_p <- tm_map(vc_p, removeNumbers)
# transform content of documents by removal of punctuation
vc_p <- tm_map(vc_p, removePunctuation)
# transform content of documents by removal of stopwords
vc_p <- tm_map(vc_p, removeWords, stopwords("en"))
# remove word 'reuter' at the end of content
vc_p <- tm_map(vc_p, removeWords, c("reuter"))
# transform content of documents by removal of multispaces
vc_p <- tm_map(vc_p, stripWhitespace)
remove(cgiDt, lsDt, topicDt)
remove(vs)
remove(allDocs, cgi, docsOfFile, files)
remove(i, ls, topic)
save.image("~/Desktop/SKOLA/Ing/2. semester/Objavovanie znalosti/Projekt/R/1.RData")
wanted <- tm_filter(vc_p, FUN = function(x){length(meta(x)[["topics_cat"]]) == 1})
wanted <- tm_filter(wanted, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
wanted_train <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
wanted_train <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
dataframe <- data.frame(text=unlist(sapply(wanted_train, `[`, "content")),
topic=unlist(sapply(wanted_train, meta, "topics_cat")),
stringsAsFactors=F)
View(dataframe)
wanted_test <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})
sourceData <- VectorSource(dataframe$text)
corpus <- Corpus(sourceData)
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
inspect(weightedDtm)
dataframe1 <- as.data.frame(dtm)
dataframe1 <- as.data.frame(inspect(dtm))
dataframe1$topic <- dataframe$topic
View(dataframe)
dataframe1 <- as.data.frame(inspect(dtm))
View(dataframe1)
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
merged <- rbind(r8train, r8test)
remove(r8train, r8test)
View(merged)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged$Class <- droplevels(merged$Class)
View(merged)
sourceData <- VectorSource(merged$docText)
corpus <- Corpus(sourceData)
corpus <- tm_map(corpus, content_transformer(tolower)) # convert to lowercase
corpus <- tm_map(corpus, removeNumbers) # remove digits
corpus <- tm_map(corpus, removePunctuation) # remove punctuation
corpus <- tm_map(corpus, stripWhitespace) # strip extra whitespace
corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
tdm <- DocumentTermMatrix(corpus)
weightedtdm <- weightTfIdf(tdm)
tdm <- as.data.frame(inspect(tdm))
weightedtdm <- as.data.frame(inspect(weightedtdm))
View(tdm)
View(weightedtdm)
tdmTrain <- tdm[which(merged$train_test == "train"),]
weightedTDMtrain <- weightedtdm[which(merged$train_test == "train"),]
View(tdmTrain)
View(weightedTDMtrain)
tdmTest <-  tdm[which(merged$train_test == "test"),]
weightedTDMtest <- weightedtdm[which(merged$train_test == "test"),]
View(merged)
View(merged)
tdmTrain$doc.class <- merged$Class[which(merged$train_test == "train")]
View(tdmTrain)
View(merged)
View(tdmTrain)
View(merged)
dataframe <- data.frame(text=unlist(sapply(wanted_train, `[`, "content")),
topic=unlist(sapply(wanted_train, meta, "topics_cat")),
stringsAsFactors=F)
wanted_train <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
library(tm)
wanted <- tm_filter(vc_p, FUN = function(x){length(meta(x)[["topics_cat"]]) == 1})
wanted <- tm_filter(wanted, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
load("3.RData")
load("1.RData")
wanted <- tm_filter(vc_p, FUN = function(x){length(meta(x)[["topics_cat"]]) == 1})
wanted <- tm_filter(wanted, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
wanted_train <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
dataframe <- data.frame(text=unlist(sapply(wanted_train, `[`, "content")),
topic=unlist(sapply(wanted_train, meta, "topics_cat")),
stringsAsFactors=F)
View(dataframe)
sourceData <- VectorSource(dataframe$text)
corpus <- Corpus(sourceData)
View(corpus)
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
inspect(dtm)
inspect(weightTfIdf())
inspect(weightedDtm
)
dataframe1 <- as.data.frame(inspect(dtm))
dataframe1$topic <- dataframe$topic
View(dataframe)
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
merged <- rbind(r8train, r8test)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged$Class <- droplevels(merged$Class)
table(merged$Class,merged$train_test)
sourceData <- VectorSource(merged$docText)
corpus <- Corpus(sourceData)
corpus <- tm_map(corpus, content_transformer(tolower)) # convert to lowercase
corpus <- tm_map(corpus, removeNumbers) # remove digits
corpus <- tm_map(corpus, removePunctuation) # remove punctuation
corpus <- tm_map(corpus, stripWhitespace) # strip extra whitespace
corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
tdm <- DocumentTermMatrix(corpus)
weightedtdm <- weightTfIdf(tdm)
tdm <- as.data.frame(inspect(tdm))
weightedtdm <- as.data.frame(inspect(weightedtdm))
tdm
tdm <- as.data.frame(inspect(tdm))
weightedtdm <- as.data.frame(inspect(weightedtdm))
tdm <- DocumentTermMatrix(corpus)
weightedtdm <- weightTfIdf(tdm)
tdm <- as.data.frame(inspect(tdm))
weightedtdm <- as.data.frame(inspect(weightedtdm))
inspect(tdm)
View(tdm)
tdm$doc.class <- merged$Class
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
merged <- rbind(r8train, r8test)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged$Class <- droplevels(merged$Class)
table(merged$Class,merged$train_test)
sourceData <- VectorSource(merged$docText)
corpus <- Corpus(sourceData)
corpus <- tm_map(corpus, content_transformer(tolower)) # convert to lowercase
corpus <- tm_map(corpus, removeNumbers) # remove digits
corpus <- tm_map(corpus, removePunctuation) # remove punctuation
corpus <- tm_map(corpus, stripWhitespace) # strip extra whitespace
corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
View(merged)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
merged <- rbind(r8train, r8test)
View(r8test)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged$Class <- droplevels(merged$Class)
table(merged$Class,merged$train_test)
help(table)
sourceData <- VectorSource(merged$docText)
corpus <- Corpus(sourceData)
View(sourceData)
View(corpus)
corpus <- tm_map(corpus, content_transformer(tolower)) # convert to lowercase
corpus <- tm_map(corpus, removeNumbers) # remove digits
corpus <- tm_map(corpus, removePunctuation) # remove punctuation
corpus <- tm_map(corpus, stripWhitespace) # strip extra whitespace
corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
tdm <- DocumentTermMatrix(corpus)
tdm
weightedtdm <- weightTfIdf(tdm)
weightedtdm
tdm <- as.data.frame(inspect(tdm))
tdm
weightedtdm <- as.data.frame(inspect(weightedtdm))
weightedtdm
inspect(weightedtdm)
str(weightedtdm)
tdm
View(tdm)
help(inspect)
inspect(tdm)
tdmTrain <- tdm[which(merged$train_test == "train"),]
help(which)
View(tdmTrain)
View(tdmTrain)
tdmTrain$doc.class <- merged$Class[which(merged$train_test == "train")]
View(tdmTrain)
load("1.RData")
wanted <- tm_filter(vc_p, FUN = function(x){length(meta(x)[["topics_cat"]]) == 1})
wanted <- tm_filter(wanted, FUN = function(x){
"crude" == meta(x)[["topics_cat"]] | "money-fx" == meta(x)[["topics_cat"]] | "trade" == meta(x)[["topics_cat"]]
})
View(wanted)
wanted_train <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
wanted_test <- tm_filter(wanted, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})
dataframe <- data.frame(text=unlist(sapply(wanted_train, `[`, "content")),
topic=unlist(sapply(wanted_train, meta, "topics_cat")),
stringsAsFactors=F)
View(dataframe)
sourceData <- VectorSource(dataframe$text)
corpus <- Corpus(sourceData)
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
inspect(dtm)
help(data.frame)
dataframe1 <- data.frame(inspect(dtm))
dataframe1$topic <- dataframe$topic
inspect(dataframe1)
dataframe1
dim(dataframe1)
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
dtm
dim(dtm)
as.matrix(dtm)
dataframe1 <- data.frame(as.matrix(dtm))
dataframe1
View(dataframe1)
dim(dataframe1)
dataframe1$topic <- dataframe$topic
head(dataframe1)
dataframe1[1, 8355:8358]
dataframe1[1, 8350:8358]
dataframe1[1, "topic"]
dataframe1[1, c("topic")]
dataframe1[1, 100:200, "trade"]
dataframe1[1, c(100:200, "trade")]
dataframe1[1, 100:200]
str(dataframe1)
str(dataframe1)
help(as.matrix)
dataframe1$topic <- meta(wanted_train)[["topics_cat"]]
dataframe1[1, "topic"]
dataframe1[1, "topic"]
dataframe1$topic <- dataframe$topic
dataframe1[1, "topic"]
dataframe1[1:10, 8350:8358]
dataframe1[10:20, 8350:8358]
dataframe1[20:30, 8350:8358]
dataframe1[30:40, 8350:8358]
dataframe1[50:60, 8350:8358]
dataframe1[60:100, 8350:8358]
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
dtm <- removeSparseTerms(dtm, 0.8)
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
dtm <- removeSparseTerms(dtm, 0.8)
dtm
dataframe1 <- data.frame(as.matrix(dtm))
dataframe1$topic <- dataframe$topic
dataframe1
View(dataframe1)
dtm <- DocumentTermMatrix(corpus)
weightedDtm <- weightTfIdf(dtm)
dtm <- removeSparseTerms(dtm, 0.9)
dtm
dataframe1 <- data.frame(as.matrix(dtm))
dataframe1$topic <- dataframe$topic
ctrl <- trainControl(method="repeatedcv", number = 10, repeats = 3)
library(caret)
ctrl <- trainControl(method="repeatedcv", number = 10, repeats = 3)
View(ctrl)
svm.tfidf.linear  <- train(topic ~ . , data=dataframe1, trControl = ctrl, method = "svmLinear")
install.packages("caret", dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
