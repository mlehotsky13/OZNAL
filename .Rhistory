tdmMatrix <- cbind(tdmMatrix, rep("train", ncol(tdmMatrix)))
tdmMatrix
rep("train", ncol(tdmMatrix))
help(rep)
c("train", "train")
c(rep("train", ncol(10)))
c(rep("train", 10))
rep("train", 10)
tdmMatrix <- cbind(tdmMatrix, train_test=rep("train", 1000))
View(lsDt)
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
tdm
tdm <- removeSparseTerms(tdm, 0.99)
tdm
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})[1000:2000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
tdm
tdm <- removeSparseTerms(tdm, 0.99)
tdm
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})[2000:3000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
tdm
tdm <- removeSparseTerms(tdm, 0.99)
tdm
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})
tdm
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
tdm
tdm <- removeSparseTerms(tdm, 0.99)
tdm
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
tdm
tdm <- removeSparseTerms(tdm, 0.99)
tdm
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
tdm <- weightTfIdf(tdm)
tdm
tdm <- removeSparseTerms(tdm, 0.99)
tdm
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[1:10, 1:10]
dim(tdm)
View(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
View(tdmMatrix)
tdmMatrix <- cbind(tdmMatrix, train_test=rep("train", 10))
View(tdmMatrix)
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[1:10, 1:10]
dim(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
View(tdmMatrix)
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
View(tdmMatrix)
tdmMatrix
dim(tdmMatrix)
tdmMatrix
tdmMatrix <- cbind(tdmMatrix, train_test=rep("train", nrows(tdmMatrix)))
tdmMatrix <- cbind(tdmMatrix, train_test=rep("train", nrow(tdmMatrix)))
tdmMatrix[1:10, 1:10]
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)
dim(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
tdmMatrix[1:10, 1:10]
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[1, 1:10]
dim(tdm)
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[1:, 1:10]
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[, 1:10]
dim(tdm)
dim(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
tdmMatrix[1:10,]
tdmMatrix <- cbind(tdmMatrix, train_test=rep("train", nrow(tdmMatrix)))
tdmMatrix[1:10,]
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[, 1:10]
dim(tdm)
tdmMatrix[1:10,]
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[, 1:10]
tdmMatrix[1:10,]
# creating matrix
tdmMatrix <- as.matrix(tdm)
tdmMatrix[1:10,]
tdmMatrix <- cbind.data.frame(tdmMatrix, train_test=rep("train", nrow(tdmMatrix)))
tdmMatrix[1:10,]
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[, 1:10]
dim(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
tdmMatrix <- cbind.data.frame(tdmMatrix, train_test=rep("train", nrow(tdmMatrix)))
tdmMatrix[1:10, 1]
tdmMatrix[1:10,]
typeof(tdmMatrix)
# get subset corpus of train documents
vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})[1:1000]
# creating Term Document Matrix
tdm <- TermDocumentMatrix(vc_p1000)[, 1:10]
dim(tdm)
# creating matrix
tdmMatrix <- as.matrix(tdm)
typeof(tdmMatrix)
tdmMatrix <- cbind.data.frame(tdmMatrix, train_test=rep("train", nrow(tdmMatrix)))
typeof(tdmMatrix)
library(tm)
library(ggplot2)
# function for processing documents inside file
processFile <- function(filepath) {
con = file(filepath, "r")
resultVector <- c()
x <- character()
while ( length(line) != 0 ) {
line = readLines(con, n = 1, encoding = "latin1")
line = gsub("&#\\d+;", "", line)
x = paste(x, line)
if ( length(line) == 0 || (length(line) != 0 && grepl("</REUTERS>", line))){
resultVector <- union(resultVector, c(x))
x <- character()
}
}
close(con)
return(resultVector)
}
# going through every .sgm file in given directory
files <- list.files(path="Dataset/reuters21578/test", pattern="*.sgm", full.names=T, recursive=FALSE)
allDocs <- c()
for (i in 1:length(files)){
docsOfFile <- processFile(files[i])
allDocs <- union(allDocs, docsOfFile)
}
# creating corpus
vs <- VectorSource(allDocs)
vc <- VCorpus(vs, readerControl = list(reader = readReut21578XMLasPlain))
# removing unnecessary meta attributes
removeMetaAttributes <- function(x){
PlainTextDocument(x,
id = meta(x, "id"),
topics = meta(x, "topics"),
topics_cat = meta(x, "topics_cat"),
lewissplit = meta(x, "lewissplit"),
cgisplit = meta(x, "cgisplit"))
}
vc <- tm_map(vc, removeMetaAttributes)
# observe documents with and without set topic
topic <- meta(vc, "topics")
topic <- unlist(topic, use.names=FALSE)
topicDt <- as.data.frame(table(topic))
# observe splits to train and test sets according to lewis
ls <- meta(vc, "lewissplit")
ls <- unlist(ls, use.names=FALSE)
lsDt <- as.data.frame(table(ls))
# observe splits to train and test sets according to cgi
cgi <- meta(vc, "cgisplit")
cgi <- unlist(cgi, use.names=FALSE)
cgiDt <- as.data.frame(table(cgi))
# PREPROCESSING of text contents
vc_p <- vc
# transform content of documents to lower case
vc_p <- tm_map(vc_p, content_transformer(tolower))
# transform content of documents by removal of numbers
vc_p <- tm_map(vc_p, removeNumbers)The.Walking.Dead.S08E16.HDTV.x264-FLEET
# transform content of documents by removal of punctuation
vc_p <- tm_map(vc_p, removePunctuation)
# transform content of documents by removal of stopwords
vc_p <- tm_map(vc_p, removeWords, stopwords("en"))
# remove word 'reuter' at the end of content
vc_p <- tm_map(vc_p, removeWords, c("reuter"))
# transform content of documents by removal of multispaces
vc_p <- tm_map(vc_p, stripWhitespace)
library(tm)
library(ggplot2)
# function for processing documents inside file
processFile <- function(filepath) {
con = file(filepath, "r")
resultVector <- c()
x <- character()
while ( length(line) != 0 ) {
line = readLines(con, n = 1, encoding = "latin1")
line = gsub("&#\\d+;", "", line)
x = paste(x, line)
if ( length(line) == 0 || (length(line) != 0 && grepl("</REUTERS>", line))){
resultVector <- union(resultVector, c(x))
x <- character()
}
}
close(con)
return(resultVector)
}
# going through every .sgm file in given directory
files <- list.files(path="Dataset/reuters21578/test", pattern="*.sgm", full.names=T, recursive=FALSE)
allDocs <- c()
for (i in 1:length(files)){
docsOfFile <- processFile(files[i])
allDocs <- union(allDocs, docsOfFile)
}
# creating corpus
vs <- VectorSource(allDocs)
vc <- VCorpus(vs, readerControl = list(reader = readReut21578XMLasPlain))
# removing unnecessary meta attributes
removeMetaAttributes <- function(x){
PlainTextDocument(x,
id = meta(x, "id"),
topics = meta(x, "topics"),
topics_cat = meta(x, "topics_cat"),
lewissplit = meta(x, "lewissplit"),
cgisplit = meta(x, "cgisplit"))
}
vc <- tm_map(vc, removeMetaAttributes)
# observe documents with and without set topic
topic <- meta(vc, "topics")
topic <- unlist(topic, use.names=FALSE)
topicDt <- as.data.frame(table(topic))
# observe splits to train and test sets according to lewis
ls <- meta(vc, "lewissplit")
ls <- unlist(ls, use.names=FALSE)
lsDt <- as.data.frame(table(ls))
# observe splits to train and test sets according to cgi
cgi <- meta(vc, "cgisplit")
cgi <- unlist(cgi, use.names=FALSE)
cgiDt <- as.data.frame(table(cgi))
# PREPROCESSING of text contents
vc_p <- vc
# transform content of documents to lower case
vc_p <- tm_map(vc_p, content_transformer(tolower))
# transform content of documents by removal of numbers
vc_p <- tm_map(vc_p, removeNumbers)
# transform content of documents by removal of punctuation
vc_p <- tm_map(vc_p, removePunctuation)
# transform content of documents by removal of stopwords
vc_p <- tm_map(vc_p, removeWords, stopwords("en"))
# remove word 'reuter' at the end of content
vc_p <- tm_map(vc_p, removeWords, c("reuter"))
# transform content of documents by removal of multispaces
vc_p <- tm_map(vc_p, stripWhitespace)
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs)
# get subset corpus of train documents
#vc_p1000 <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
# creating Term Document Matrix
#tdm <- TermDocumentMatrix(vc_p1000)[, 1:10]
#dim(tdm)
# creating matrix
#tdmMatrix <- as.matrix(tdm)
#tdmMatrix <- cbind.data.frame(tdmMatrix, train_test=rep("train", nrow(tdmMatrix)))
#freq <- sort(rowSums(tdmMatrix), decreasing=TRUE)
#wf <- data.frame(word=names(freq), freq=freq)
# construct graph of term frequencies
#p <- ggplot(subset(wf, freq>100), aes(x = reorder(word, -freq), y = freq)) +
#  geom_bar(stat = "identity") +
#  theme(axis.text.x=element_text(angle=45, hjust=1))
#p
#findFreqTerms(tdm, 50)
#findAssocs(tdm, "said", 0.7)
#tdm_p <- removeSparseTerms(tdm, 0.8)
#inspect(tdm_p)
#library(reshape2)
#TDM.dense = melt(tdm.dense, value.name = "count")
#head(tdm.dense)
#weightedtdm <- weightTfIdf(tdm)
#as.matrix(weightedtdm)[10:20,200:210]
tdm <- TermDocumentMatrix(vc_p)
tdm
tdm_tfidf <- weightTfIdf(tdm)
tdm_tfidf
tdm
tdm_df <- as.data.frame(tdm)
tdm_df <- as.data.frame(inspect(tdm))
tdm_df
tdm_tfidf_df <- as.data.frame(inspect(tdm_tfidf))
tdm_tfidf_df
tdm_train <- TermDocumentMatrix(vc_p_train)
tdm_tfidf_train <- weightTfIdf(tdm_train)
tdm_test <- TermDocumentMatrix(vc_p_test)
tdm_tfidf_test <- weightTfIdf(tdm_test)
vc_p_train <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
vc_p_test <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})
tdm_train <- TermDocumentMatrix(vc_p_train)
tdm_tfidf_train <- weightTfIdf(tdm_train)
tdm_test <- TermDocumentMatrix(vc_p_test)
tdm_tfidf_test <- weightTfIdf(tdm_test)
df_train <- as.data.frame(inspect(tdm_train))
df_tfidf_train <- as.data.frame(inspect(tdm_tfidf_train))
df_test <- as.data.frame(inspect(tdm_test))
df_tfidf_test <- as.data.frame(inspect(tdm_tfidf_test))
df_train
df_tdidf_train
df_tfidf_train
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
r8test
str(r8train)
r8train[1:10]
r8train[1:10,]
r8train[1:12,]
r8train[1:2,]
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
str(r8train)
r8train[1:2,]
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
str(r8train)
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
str(r8train)
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
str(r8train)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
str(r8train)
r8train[1:2,]
r8test[1:2,]
merged <- rbind(r8train, r8test)
str(merged)
str(merged)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
r8test[1:2,]
merged[1:2,]
merged$Class <- droplevels(merged$Class)
str(merged)
help("droplevels")
merged$Class <- droplevels(merged$Class)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
merged <- rbind(r8train, r8test)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged$Class <- droplevels(merged$Class)
table(merged$Class,merged$train_test)
sourceData <- VectorSource(merged$docText)
corpus <- Corpus(sourceData)
corpus <- tm_map(corpus, content_transformer(tolower)) # convert to lowercase
corpus <- tm_map(corpus, removeNumbers) # remove digits
corpus <- tm_map(corpus, removePunctuation) # remove punctuation
corpus <- tm_map(corpus, stripWhitespace) # strip extra whitespace
corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
tdm <- DocumentTermMatrix(corpus)
weightedtdm <- weightTfIdf(tdm)
findFreqTerms(tdm, 250)
tdm <- as.data.frame(inspect(tdm))
weightedtdm <- as.data.frame(inspect(weightedtdm))
tdm[1:10,]
str(tdm)
tdm
tdmTrain <- tdm[which(merged$train_test == "train"),]
tdmTrain
tdmTrain[1:10,]
weightedTDMtrain <- weightedtdm[which(merged$train_test == "train"),]
tdmTest <-  tdm[which(merged$train_test == "test"),]
weightedTDMtest <- weightedtdm[which(merged$train_test == "test"),]
tdmTrain[1:10,]
tdmTrain$doc.class <- merged$Class[which(merged$train_test == "train")]
tdmTrain[1:10, 1]
tdmTrain[1:10, ]
tdmTest[1:10, ]
tdmTest$doc.class <- merged$Class[which(merged$train_test == "test")]
tdmTest[1:10, ]
weightedTDMtrain[1:10,]
weightedTDMtrain$doc.class <- merged$Class[which(merged$train_test == "train")]
weightedTDMtrain[1:10,]
weightedTDMtest$doc.class  <- merged$Class[which(merged$train_test == "test")]
# create data frames
df_train <- as.data.frame(inspect(tdm_train))
tdm_train <- TermDocumentMatrix(vc_p_train)
tdm_tfidf_train <- weightTfIdf(tdm_train)
tdm_test <- TermDocumentMatrix(vc_p_test)
tdm_tfidf_test <- weightTfIdf(tdm_test)
load("3.RData")
vc_p_train <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
vc_p_test <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs)
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs, vc_p)
tdm_train <- TermDocumentMatrix(vc_p_train)
tdm_tfidf_train <- weightTfIdf(tdm_train)
tdm_test <- TermDocumentMatrix(vc_p_test)
tdm_tfidf_test <- weightTfIdf(tdm_test)
# create data frames
df_train <- as.data.frame(inspect(tdm_train))
str(df_train)
df_train[1:10,]
df_train["train_test"] <- c("train")
df_train[1:10,]
# create data frames
df_train <- as.data.frame(inspect(tdm_train))
library(tm)
r8train <- read.table("r8-train-all-terms.txt", header=FALSE, sep='\t')
r8test <- read.table("r8-test-all-terms.txt", header=FALSE, sep='\t')
names(r8train) <- c("Class", "docText")
names(r8test) <- c("Class", "docText")
r8train$docText <- as.character(r8train$docText)
r8test$docText <- as.character(r8test$docText)
r8train$train_test <- c("train")
r8test$train_test <- c("test")
merged <- rbind(r8train, r8test)
remove(r8train, r8test)
merged <- merged[which(merged$Class %in% c("crude","money-fx","trade")),]
merged$Class <- droplevels(merged$Class)
table(merged$Class,merged$train_test)
sourceData <- VectorSource(merged$docText)
corpus <- Corpus(sourceData)
corpus <- tm_map(corpus, content_transformer(tolower)) # convert to lowercase
corpus <- tm_map(corpus, removeNumbers) # remove digits
corpus <- tm_map(corpus, removePunctuation) # remove punctuation
corpus <- tm_map(corpus, stripWhitespace) # strip extra whitespace
corpus <- tm_map(corpus, removeWords, stopwords('english')) # remove stopwords
tdm <- DocumentTermMatrix(corpus)
weightedtdm <- weightTfIdf(tdm)
tdm <- as.data.frame(inspect(tdm))
weightedtdm <- as.data.frame(inspect(weightedtdm))
tdmTrain <- tdm[which(merged$train_test == "train"),]
weightedTDMtrain <- weightedtdm[which(merged$train_test == "train"),]
tdmTest <-  tdm[which(merged$train_test == "test"),]
weightedTDMtest <- weightedtdm[which(merged$train_test == "test"),]
tdmTrain$doc.class <- merged$Class[which(merged$train_test == "train")]
tdmTest$doc.class <- merged$Class[which(merged$train_test == "test")]
weightedTDMtrain$doc.class <- merged$Class[which(merged$train_test == "train")]
weightedTDMtest$doc.class  <- merged$Class[which(merged$train_test == "test")]
tdmTrain[1:10,]
df_train$topic <- c("bla")
load("3.RData")
vc_p_train <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TRAIN"})
vc_p_test <- tm_filter(vc_p, FUN = function(x){meta(x)[["lewissplit"]] == "TEST"})
# remove unused structures
remove(allDocs, cgi, docsOfFile, files, i, ls, topic, cgiDt, lsDt, topicDt, vc, vs)
tdm_train <- TermDocumentMatrix(vc_p_train)
tdm_tfidf_train <- weightTfIdf(tdm_train)
tdm_test <- TermDocumentMatrix(vc_p_test)
tdm_tfidf_test <- weightTfIdf(tdm_test)
# create data frames
df_train <- as.data.frame(inspect(tdm_train))
df_train[1:10.]
df_train[1:10,]
df_train$topic <- c("bla")
df_train[1:10,]
df_train$topic <- vc_p_train$metadata$topics
df_train[1:10,]
View(vc_p)
View(vc_p_train)
df_train$topic <- vc_p_train$meta$topics_cat
df_train[1:10,]
